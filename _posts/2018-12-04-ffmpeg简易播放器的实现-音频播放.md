基于FFmpeg和SDL实现的简易视频播放器，主要分为读取视频文件解码和调用SDL显示两大部分。详细流程可参考代码注释。  
本篇实验笔记主要参考如下两篇文章：  
[1]. [最简单的基于FFMPEG+SDL的视频播放器ver2(采用SDL2.0)](https://blog.csdn.net/leixiaohua1020/article/details/38868499)  
[2]. [An ffmpeg and SDL Tutorial](https://blog.csdn.net/leixiaohua1020/article/details/38868499)   

## 1. 视频播放器基本原理  
下图引用自“[雷霄骅，视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)”，因原图太小，看不太清楚，故重新制作了一张图片。  
![播放器基本原理示意图](https://leihl.github.io/img/ffmpeg_player/01_player_flow.jpg "播放器基本原理示意图")  
如下内容引用自“[雷霄骅，视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)”：  
>**解协议**  
将流媒体协议的数据，解析为标准的相应的封装格式数据。视音频在网络上传播的时候，常常采用各种流媒体协议，例如HTTP，RTMP，或是MMS等等。这些协议在传输视音频数据的同时，也会传输一些信令数据。这些信令数据包括对播放的控制（播放，暂停，停止），或者对网络状态的描述等。解协议的过程中会去除掉信令数据而只保留视音频数据。例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。
>
>**解封装**  
将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据。封装格式种类很多，例如MP4，MKV，RMVB，TS，FLV，AVI等等，它的作用就是将已经压缩编码的视频数据和音频数据按照一定的格式放到一起。例如，FLV格式的数据，经过解封装操作后，输出H.264编码的视频码流和AAC编码的音频码流。
>
>**解码**  
将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。音频的压缩编码标准包含AAC，MP3，AC-3等等，视频的压缩编码标准则包含H.264，MPEG2，VC-1等等。解码是整个系统中最重要也是最复杂的一个环节。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV420P，RGB等等；压缩编码的音频数据输出成为非压缩的音频抽样数据，例如PCM数据。
>
>**音视频同步**  
根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显卡和声卡播放出来。

## 2. 简易播放器的实现-音频播放  
### 2.1 实验平台
实验平台：openSUSE Leap 42.3  
FFmpeg版本：4.1  
SDL版本：2.0.9  
FFmpeg开发环境搭建可参考“[ffmpeg开发环境构建](https://www.cnblogs.com/leisure_chn/p/10035365.html)”  

### 2.2 源码清单  
```c

```
#### 2.2.1 源码流程简述  
流程比较简单，不画流程图了，简述如下：  
```
media file --[decode]--> raw frame --[scale]--> yuv frame --[SDL]--> display  
media file ------------> p_frm_raw -----------> p_frm_yuv ---------> sdl_renderer  
```
加上相关关键函数后，流程如下：  
```
media_file ---[av_read_frame()]----------->  
p_packet   ---[avcodec_send_packet()]----->  
decoder    ---[avcodec_receive_frame()]--->  
p_frm_raw  ---[sws_scale()]--------------->  
p_frm_yuv  ---[SDL_UpdateYUVTexture()]---->  
display  
```

#### 2.2.2 源码中涉及的相关概念  
源码清单中涉及的一些概念简述如下：  
**container:**  
对应数据结构AVFormatContext  
封装器，将流数据封装为指定格式的文件，文件格式如AVI、MP4等。  
FFmpeg可识别五种流类型：视频video(v)、音频audio(a)、attachment(t)、数据data(d)、字幕subtitle。  

**codec:**  
对应数据结构AVCodec  
编解码器。编码器将未压缩的原始图像或音频数据编码为压缩数据。解码器与之相反。  

**codec context**:  
对应数据结构AVCodecContext  
编解码器上下文。此为非常重要的一个数据结构，后文分析。各API大量使用AVCodecContext来引用编解码器。  

**codec par**:  
对应数据结构AVCodecParameters  
编解码器参数。新版本增加的字段。新版本建议使用AVStream->codepar替代AVStream->codec。  

**packet**:  
对应数据结构AVPacket  
经过编码的数据。通过av_read_frame()从媒体文件中获取得到的一个packet可能包含多个(整数个)音频帧或单个
视频帧，或者其他类型的流数据。  

**frame**:  
对应数据结构AVFrame  
解码后的原始数据。解码器将packet解码后生成frame。  

#### 2.2.3 帧率控制-定时刷新机制  
将上一版代码拆分为两个线程：定时刷新线程 + 解码主线程。  
定时刷新线程每40ms发送一个自定义SDL事件，通知解码主线程  
解码主线程收到SDL事件后，获取一个视频帧解码并显示  

### 2.3 编译
```shell
gcc -o ffplayer ffplayer.c -lavutil -lavformat -lavcodec -lavutil -lswscale -lSDL2
```

### 2.4 测试
```shell
./ffplayer 480x272.h265 
```

## 3. 参考资料  
[1] 雷霄骅，[视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)  
[2] 雷霄骅，[FFmpeg源代码简单分析：常见结构体的初始化和销毁(AVFormatContext，AVFrame等)](https://blog.csdn.net/leixiaohua1020/article/details/41181155)  
[3] 雷霄骅，[最简单的基于FFMPEG+SDL的视频播放器ver2(采用SDL2.0)](https://blog.csdn.net/leixiaohua1020/article/details/38868499)  
[4] Martin Bohme, [An ffmpeg and SDL Tutorial, Tutorial 01: Making Screencaps](http://dranger.com/ffmpeg/ffmpegtutorial_all.html#tutorial01.html)  
[5] Martin Bohme, [An ffmpeg and SDL Tutorial, Tutorial 02: Outputting to the Screen](http://dranger.com/ffmpeg/ffmpegtutorial_all.html#tutorial02.html)  
[6] [YUV图像里的stride和plane的解释](https://www.cnblogs.com/welhzh/p/4939613.html)  
[7] [图文详解YUV420数据格式](https://www.cnblogs.com/azraelly/archive/2013/01/01/2841269.html)  
[8] [YUV](https://zh.wikipedia.org/wiki/YUV)，<https://zh.wikipedia.org/wiki/YUV>  

## 4. 修改记录  
2018-11-23  V1.0  初稿  
2018-11-29  V1.1  增加定时刷新线程，使解码帧率更加准确  