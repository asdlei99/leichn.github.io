ffplay是FFmpeg工程自带的简单播放器，使用FFmpeg提供的解码器和SDL进行视频播放。  
ffplay虽是一个简单的播放器，但代码量不少，也涉及很多概念，分析起来比较复杂烦琐。  
个人感觉分析过程还是有些困难的，加之杂事很多时间不多，分析过程断断续续持续了挺长一段时间。  

ffplay源码路径为“ffmpeg-4.1/fftools/ffplay.c”，“ffmpeg-4.1”为FFmpeg工程顶层目录，版本为4.1。  
本文主要从如下几个方面进行分析：  
[1]. 各工作线程的功能及数据流向
[2]. 音视频同步的实现方式，ffplay播放器中最核心的内容  
[3]. 播放/暂停的实现方式  
[4]. 指定播放点播放(seek，拖动进度条，快进/快退)的实现方式

在尝试分析源码前，应先阅读如下参考文章：  
[1]. [雷霄骅，视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)”  

## 1. 基本原理
###1.1 播放器基本原理  
下图引用自“[雷霄骅，视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)”，因原图太小，看不太清楚，故重新制作了一张图片。  
![播放器基本原理示意图](https://leihl.github.io/img/ffmpeg_player/01_player_flow.jpg "播放器基本原理示意图")  
如下内容引用自“[雷霄骅，视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)”：  
>**解协议**  
将流媒体协议的数据，解析为标准的相应的封装格式数据。视音频在网络上传播的时候，常常采用各种流媒体协议，例如HTTP，RTMP，或是MMS等等。这些协议在传输视音频数据的同时，也会传输一些信令数据。这些信令数据包括对播放的控制（播放，暂停，停止），或者对网络状态的描述等。解协议的过程中会去除掉信令数据而只保留视音频数据。例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。
>
>**解封装**  
将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据。封装格式种类很多，例如MP4，MKV，RMVB，TS，FLV，AVI等等，它的作用就是将已经压缩编码的视频数据和音频数据按照一定的格式放到一起。例如，FLV格式的数据，经过解封装操作后，输出H.264编码的视频码流和AAC编码的音频码流。
>
>**解码**  
将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。音频的压缩编码标准包含AAC，MP3，AC-3等等，视频的压缩编码标准则包含H.264，MPEG2，VC-1等等。解码是整个系统中最重要也是最复杂的一个环节。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV420P，RGB等等；压缩编码的音频数据输出成为非压缩的音频抽样数据，例如PCM数据。
>
>**音视频同步**  
根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显卡和声卡播放出来。

###1.2 FFmpeg转码流程
<pre>
 _______              ______________
|       |            |              |
| input |  demuxer   | encoded data |   decoder
| file  | ---------> | packets      | -----+
|_______|            |______________|      |
                                           v
                                       _________
                                      |         |
                                      | decoded |
                                      | frames  |
                                      |_________|
 ________             ______________       |
|        |           |              |      |
| output | <-------- | encoded data | <----+
| file   |   muxer   | packets      |   encoder
|________|           |______________|

</pre>
`ffmpeg`调用libavformat库(包含解复用器demuxer)，从输入文件中读取到包含编码数据的包(packet)。如果有多个输入文件，`ffmpeg`尝试追踪多个有效输入流的最小时间戳(timestamp)，用这种方式实现多个输入文件的同步。

然后编码包被传递到解码器(decoder)，解码器解码后生成原始帧(frame)，原始帧可以被滤镜(filter)处理(图中未画滤镜)，经滤镜处理后的帧送给编码器，编码器将之编码后输出编码包。最终，由复用器(muxex)将编码码写入特定封装格式的输出文件。

ffplay不需要编码过程，是将上图中的解码后帧送往屏幕显示。

## 2. 代码框架与处理流程

### 2.1 流程图

**packet**：未解码的压缩数据包
**frame**：解码后的原始数据包

### 2.2 关键数据结构


### 2.2 主线程：event_loop()
**主线程主要实现三项功能：视频播放(音视频同步)、字幕播放、SDL消息处理**  
音频播放由SDL库内建线程实现。

#### 2.2.1 视频播放  

#### 2.2.2 SDL消息处理

### 2.3 解复用线程：read_thread()
**解复用线程读取视频文件，将取到的packet根据类型存入不同是packet队列中。packet队列有音频packet队列、视频packet队列和字幕packet队列**  

### 2.4 视频解码线程：video_thread()
**视频解码线程从视频packet队列中取数据，解码后存入视频frame队列**  

#### 2.4.1 video_thread()
视频解码线程将解码后的帧放入frame队列中。为节省篇幅，如下源码中删除了滤镜filter相关代码。  
```c
// 视频解码线程：从视频packet_queue中取数据，解码后放入视频frame_queue
static int video_thread(void *arg)
{
    VideoState *is = arg;
    AVFrame *frame = av_frame_alloc();
    double pts;
    double duration;
    int ret;
    AVRational tb = is->video_st->time_base;
    AVRational frame_rate = av_guess_frame_rate(is->ic, is->video_st, NULL);

    if (!frame) {
        return AVERROR(ENOMEM);
    }

    for (;;) {
        ret = get_video_frame(is, frame);
        if (ret < 0)
            goto the_end;
        if (!ret)
            continue;
		
		// 当前帧播放时长
		duration = (frame_rate.num && frame_rate.den ? av_q2d((AVRational){frame_rate.den, frame_rate.num}) : 0);
		// 当前帧显示时间戳
		pts = (frame->pts == AV_NOPTS_VALUE) ? NAN : frame->pts * av_q2d(tb);
		// 将当前帧压入frame_queue
		ret = queue_picture(is, frame, pts, duration, frame->pkt_pos, is->viddec.pkt_serial);
		av_frame_unref(frame);

        if (ret < 0)
            goto the_end;
    }
the_end:
    av_frame_free(&frame);
    return 0;
}
```

#### 2.4.2 get_video_frame()
从packet队列中取一个packet解码得到一个frame，并判断是否要根据framedrop机制丢弃失去同步的视频帧。参考源码中注释：  
```c
static int get_video_frame(VideoState *is, AVFrame *frame)
{
    int got_picture;

    if ((got_picture = decoder_decode_frame(&is->viddec, frame, NULL)) < 0)
        return -1;

    if (got_picture) {
        double dpts = NAN;

        if (frame->pts != AV_NOPTS_VALUE)
            dpts = av_q2d(is->video_st->time_base) * frame->pts;

        frame->sample_aspect_ratio = av_guess_sample_aspect_ratio(is->ic, is->video_st, frame);

        // ffplay文档中对"-framedrop"选项的说明: 
        //   Drop video frames if video is out of sync.Enabled by default if the master clock is not set to video.
        //   Use this option to enable frame dropping for all master clock sources, use - noframedrop to disable it.
        // "-framedrop"选项用于设置当视频帧失去同步时，是否丢弃视频帧。"-framedrop"选项以bool方式改变变量framedrop值。
        // 音视频同步方式有三种：A同步到视频，B同步到音频，C同步到外部时钟。
        // 1) 当命令行不带"-framedrop"选项或"-noframedrop"时，framedrop值为默认值-1，若同步方式是"同步到视频"
        //    则不丢弃失去同步的视频帧，否则将丢弃失去同步的视频帧。
        // 2) 当命令行带"-framedrop"选项时，framedrop值为1，无论何种同步方式，均丢弃失去同步的视频帧。
        // 3) 当命令行带"-noframedrop"选项时，framedrop值为0，无论何种同步方式，均不丢弃失去同步的视频帧。
        if (framedrop>0 || (framedrop && get_master_sync_type(is) != AV_SYNC_VIDEO_MASTER)) {
            if (frame->pts != AV_NOPTS_VALUE) {
                double diff = dpts - get_master_clock(is);
                if (!isnan(diff) && fabs(diff) < AV_NOSYNC_THRESHOLD &&
                    diff - is->frame_last_filter_delay < 0 &&
                    is->viddec.pkt_serial == is->vidclk.serial &&
                    is->videoq.nb_packets) {
                    is->frame_drops_early++;
                    av_frame_unref(frame);  // 视频帧失去同步则直接扔掉
                    got_picture = 0;
                }
            }
        }
    }

    return got_picture;
}
```
ffplay中framedrop处理有两种，一处是此处解码后得到的frame尚未存入frame队列前，以is->frame_drops_early++为标记；另一处是frame队列中读取frame进行显示的时候，以is->frame_drops_late++为标记。  
本处framedrop操作涉及的变量is->frame_last_filter_delay属于滤镜filter操作相关，ffplay中默认是关闭滤镜的，本文不考虑滤镜相关操作。  

#### 2.4.3 decoder_decode_frame()
这个函数是很核心的一个函数，可以解码视频帧和音频帧。视频解码线程中，视频帧实际的解码操作就在此函数中进行。  
```c
// 从packet_queue中取一个packet，解码生成frame
static int decoder_decode_frame(Decoder *d, AVFrame *frame, AVSubtitle *sub) {
    int ret = AVERROR(EAGAIN);

    for (;;) {
        AVPacket pkt;

        // 本函数被各解码线程(音频、视频、字幕)首次调用时，d->pkt_serial等于-1，d->queue->serial等于1
        if (d->queue->serial == d->pkt_serial) {
            do {
                if (d->queue->abort_request)
                    return -1;

                // 3. 从解码器接收frame
                switch (d->avctx->codec_type) {
                    case AVMEDIA_TYPE_VIDEO:
                        // 3.1 一个视频packet含一个视频frame
                        //     解码器缓存一定数量的packet后，才有解码后的frame输出
                        //     frame输出顺序是按pts的顺序，如IBBPBBP
                        //     frame->pkt_pos变量是此frame对应的packet在视频文件中的偏移地址，值同pkt.pos
                        ret = avcodec_receive_frame(d->avctx, frame);
                        if (ret >= 0) {
                            if (decoder_reorder_pts == -1) {
                                frame->pts = frame->best_effort_timestamp;
                            } else if (!decoder_reorder_pts) {
                                frame->pts = frame->pkt_dts;
                            }
                        }
                        break;
                    case AVMEDIA_TYPE_AUDIO:
                        // 3.2 一个音频packet含多个音频frame，每次avcodec_receive_frame()返回一个frame，此函数返回。
                        // 下次进来此函数，继续获取一个frame，直到avcodec_receive_frame()返回AVERROR(EAGAIN)，
                        // 表示解码器需要填入新的音频packet
                        ret = avcodec_receive_frame(d->avctx, frame);
                        if (ret >= 0) {
                            AVRational tb = (AVRational){1, frame->sample_rate};
                            if (frame->pts != AV_NOPTS_VALUE)
                                frame->pts = av_rescale_q(frame->pts, d->avctx->pkt_timebase, tb);
                            else if (d->next_pts != AV_NOPTS_VALUE)
                                frame->pts = av_rescale_q(d->next_pts, d->next_pts_tb, tb);
                            if (frame->pts != AV_NOPTS_VALUE) {
                                d->next_pts = frame->pts + frame->nb_samples;
                                d->next_pts_tb = tb;
                            }
                        }
                        break;
                }
                if (ret == AVERROR_EOF) {
                    d->finished = d->pkt_serial;
                    avcodec_flush_buffers(d->avctx);
                    return 0;
                }
                if (ret >= 0)
                    return 1;   // 成功解码得到一个视频帧或一个音频帧，则返回
            } while (ret != AVERROR(EAGAIN));
        }

        do {
            if (d->queue->nb_packets == 0)  // packet_queue为空则等待
                SDL_CondSignal(d->empty_queue_cond);
            if (d->packet_pending) {        // 有未处理的packet则先处理
                av_packet_move_ref(&pkt, &d->pkt);
                d->packet_pending = 0;
            } else {
                // 1. 取出一个packet。使用pkt对应的serial赋值给d->pkt_serial
                if (packet_queue_get(d->queue, &pkt, 1, &d->pkt_serial) < 0)
                    return -1;
            }
        } while (d->queue->serial != d->pkt_serial);

        // packet_queue中第一个总是flush_pkt。每次seek操作会插入flush_pkt，更新serial，开启新的播放序列
        if (pkt.data == flush_pkt.data) {
            // 复位解码器内部状态/刷新内部缓冲区。当seek操作或切换流时应调用此函数。
            avcodec_flush_buffers(d->avctx);
            d->finished = 0;
            d->next_pts = d->start_pts;
            d->next_pts_tb = d->start_pts_tb;
        } else {
            if (d->avctx->codec_type == AVMEDIA_TYPE_SUBTITLE) {
                int got_frame = 0;
                ret = avcodec_decode_subtitle2(d->avctx, sub, &got_frame, &pkt);
                if (ret < 0) {
                    ret = AVERROR(EAGAIN);
                } else {
                    if (got_frame && !pkt.data) {
                       d->packet_pending = 1;
                       av_packet_move_ref(&d->pkt, &pkt);
                    }
                    ret = got_frame ? 0 : (pkt.data ? AVERROR(EAGAIN) : AVERROR_EOF);
                }
            } else {
                // 2. 将packet发送给解码器
                //    发送packet的顺序是按dts递增的顺序，如IPBBPBB
                //    pkt.pos变量可以标识当前packet在视频文件中的地址偏移
                if (avcodec_send_packet(d->avctx, &pkt) == AVERROR(EAGAIN)) {
                    av_log(d->avctx, AV_LOG_ERROR, "Receive_frame and send_packet both returned EAGAIN, which is an API violation.\n");
                    d->packet_pending = 1;
                    av_packet_move_ref(&d->pkt, &pkt);
                }
            }
            av_packet_unref(&pkt);
        }
    }
}
```
本函数实现如下功能：  
[1]. 从视频packet队列中取一个packet  
[2]. 将取得的packet发送给解码器  
[3]. 从解码器接收解码后的frame，此frame作为函数的输出参数供上级函数处理  
注意如下几点：  
[1]. 含B帧的视频文件，其视频帧存储顺序与显示顺序不同，参[]  
[2]. 解码器的输入是packet队列，视频帧解码顺序与存储顺序相同，是按dts递增的顺序。dts是解码时间戳，因此存储顺序解码顺序都是dts递增的顺序。avcodec_send_packet()就是将视频文件中的packet序列依次发送给解码器。发送packet的顺序如IPBBPBB。  
[3]. 解码器的输出是frame队列，frame输出顺序是按pts递增的顺序。pts是解码时间戳。pts与dts不一致的问题由解码器进行了处理，用户程序不必关心。从解码器接收frame的顺序如IBBPBBP。  
[4]. 解码器中会缓存一定数量的帧，一个新的解码动作启动后，向解码器送入好几个packet解码器才会输出第一个packet，这比较容易理解，因为解码时帧之间有信赖关系，例如IPB三个帧被送入解码器后，B帧解码需要依赖I帧和P帧，所在在B帧输出前，I帧和P帧必须存在于解码器中而不能删除。理解了这一点，后面视频frame队列中对视频帧的显示和删除机制才容易理解。  
[5]. 解码器中缓存的帧可以通过冲洗(flush)解码器取出。冲洗(flush)解码器的方法就是调用avcodec_send_packet(..., NULL)，然后多次调用avcodec_receive_frame()将缓存帧取尽。缓存帧取完后，avcodec_receive_frame()返回AVERROR_EOF。ffplay中，是通过向解码器发送flush_pkt(实际为NULL)，每次seek操作都会向解码器发送flush_pkt。

如何确定解码器的输出frame与输入packet的对应关系呢？可以对比frame->pkt_pos和pkt.pos的值，这两个值表示packet在视频文件中的偏移地址，如果这两个变量值相等，表示此frame来自此packet。调试跟踪这两个变量值，即能发现解码器输入帧与输出帧的关系。为简便，就不贴图了。  

### 2.5 音频解码线程：audio_thread()
**音频解码线程从音频packet队列中取数据，解码后存入音频frame队列**  

### 2.6 字幕解码线程：subtitle_thread()
略。以后有机会研究字幕时，再作补充。

### 2.7 音频播放线程


## 2. 音视频同步  

注意：  
[1]. 一个音频packet中含有多个完整的音频帧，因此一次avcodec_send_packet()后，会多次调用avcodec_receive_frame()来将这一个packet解码后的数据接收完。  
[2]. 解码器内部会有缓冲机制，会缓存一定量的音频帧，不冲洗(flush)解码器的话，缓存帧是取不出来的，未冲洗(flush)解码器情况下，avcodec_receive_frame()返回AVERROR(EAGAIN)，表示解码器中改取的帧已取完了(当然缓存帧还是在的)，需要用avcodec_send_packet()向解码器提供新数据。  
[3]. 文件播放完毕时，应冲洗(flush)解码器。冲洗(flush)解码器的方法就是调用avcodec_send_packet(..., NULL)，然后按之前同样的方式多次调用avcodec_receive_frame()将缓存帧取尽。缓存帧取完后，avcodec_receive_frame()返回AVERROR_EOF。  



## 3. 参考资料  
[1] 雷霄骅，[视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)  
[2] 雷霄骅，[最简单的基于FFMPEG+SDL的视频播放器ver2(采用SDL2.0)](https://blog.csdn.net/leixiaohua1020/article/details/38868499)  
[3] SDL WIKI, <https://wiki.libsdl.org/>  
[4] Martin Bohme, [An ffmpeg and SDL Tutorial, Tutorial 05: Synching Video](http://dranger.com/ffmpeg/ffmpegtutorial_all.html#tutorial05.html)  

http://www.cnblogs.com/zhangming-blog/articles/6000518.html  
https://blog.csdn.net/abcsunl/article/details/68190136  
https://www.jianshu.com/p/04b5b1e4ff27  
https://blog.csdn.net/aokewood/article/details/6893699  

## 4. 修改记录  
2018-12-28  V1.0  初稿  