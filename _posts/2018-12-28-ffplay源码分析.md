ffplay是FFmpeg工程自带的简单播放器，使用FFmpeg提供的解码器和SDL进行视频播放。  
ffplay虽是一个简单的播放器，但代码量不少，也涉及很多概念，分析起来比较复杂烦琐。  
个人感觉分析过程还是有些困难的，加之杂事很多时间不多，分析过程断断续续持续了挺长一段时间。  

ffplay源码路径为“ffmpeg-4.1/fftools/ffplay.c”，“ffmpeg-4.1”为FFmpeg工程顶层目录，版本为4.1。  
本文主要从如下几个方面进行分析：  
[1]. 各工作线程的功能及数据流向
[2]. 音视频同步的实现方式，ffplay播放器中最核心的内容  
[3]. 播放/暂停的实现方式  
[4]. 指定播放点播放(seek，拖动进度条，快进/快退)的实现方式

在尝试分析源码前，应先阅读如下参考文章：  
[1]. [雷霄骅，视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)”  


## 1. 播放器基本原理  
下图引用自“[雷霄骅，视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)”，因原图太小，看不太清楚，故重新制作了一张图片。  
![播放器基本原理示意图](https://leihl.github.io/img/ffmpeg_player/01_player_flow.jpg "播放器基本原理示意图")  
如下内容引用自“[雷霄骅，视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)”：  
>**解协议**  
将流媒体协议的数据，解析为标准的相应的封装格式数据。视音频在网络上传播的时候，常常采用各种流媒体协议，例如HTTP，RTMP，或是MMS等等。这些协议在传输视音频数据的同时，也会传输一些信令数据。这些信令数据包括对播放的控制（播放，暂停，停止），或者对网络状态的描述等。解协议的过程中会去除掉信令数据而只保留视音频数据。例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。
>
>**解封装**  
将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据。封装格式种类很多，例如MP4，MKV，RMVB，TS，FLV，AVI等等，它的作用就是将已经压缩编码的视频数据和音频数据按照一定的格式放到一起。例如，FLV格式的数据，经过解封装操作后，输出H.264编码的视频码流和AAC编码的音频码流。
>
>**解码**  
将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。音频的压缩编码标准包含AAC，MP3，AC-3等等，视频的压缩编码标准则包含H.264，MPEG2，VC-1等等。解码是整个系统中最重要也是最复杂的一个环节。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV420P，RGB等等；压缩编码的音频数据输出成为非压缩的音频抽样数据，例如PCM数据。
>
>**音视频同步**  
根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显卡和声卡播放出来。

###1.2 FFmpeg转码流程
空对空

## 2. 代码框架与处理流程

### 2.1 流程图

**packet**：未解码的压缩数据包
**frame**：解码后的原始数据包

### 2.2 关键数据结构


### 2.2 主线程：event_loop()
**主线程主要实现三项功能：视频播放(音视频同步)、字幕播放、SDL消息处理**  
音频播放由SDL库内建线程实现。  

### 2.3 解复用线程：read_thread()
**解复用线程读取视频文件，将取到的packet根据类型存入不同是packet队列中。packet队列有音频packet队列、视频packet队列和字幕packet队列**  

### 2.4 视频解码线程：video_thread()
**视频解码线程从视频packet队列中取数据，解码后存入视频frame队列**  

#### 2.4.1 get_video_frame()
从packet队列中取一个packet解码得到一个frame，并判断是否要根据framedrop机制丢弃失去同步的视频帧。参考源码中注释：  
```c
static int get_video_frame(VideoState *is, AVFrame *frame)
{
    int got_picture;

    if ((got_picture = decoder_decode_frame(&is->viddec, frame, NULL)) < 0)
        return -1;

    if (got_picture) {
        double dpts = NAN;

        if (frame->pts != AV_NOPTS_VALUE)
            dpts = av_q2d(is->video_st->time_base) * frame->pts;

        frame->sample_aspect_ratio = av_guess_sample_aspect_ratio(is->ic, is->video_st, frame);

        // ffplay文档中对"-framedrop"选项的说明: 
        //   Drop video frames if video is out of sync.Enabled by default if the master clock is not set to video.
        //   Use this option to enable frame dropping for all master clock sources, use - noframedrop to disable it.
        // "-framedrop"选项用于设置当视频帧失去同步时，是否丢弃视频帧。"-framedrop"选项以bool方式改变变量framedrop值。
        // 音视频同步方式有三种：A同步到视频，B同步到音频，C同步到外部时钟。
        // 1) 当命令行不带"-framedrop"选项或"-noframedrop"时，framedrop值为默认值-1，若同步方式是"同步到视频"
        //    则不丢弃失去同步的视频帧，否则将丢弃失去同步的视频帧。
        // 2) 当命令行带"-framedrop"选项时，framedrop值为1，无论何种同步方式，均丢弃失去同步的视频帧。
        // 3) 当命令行带"-noframedrop"选项时，framedrop值为0，无论何种同步方式，均不丢弃失去同步的视频帧。
        if (framedrop>0 || (framedrop && get_master_sync_type(is) != AV_SYNC_VIDEO_MASTER)) {
            if (frame->pts != AV_NOPTS_VALUE) {
                double diff = dpts - get_master_clock(is);
                if (!isnan(diff) && fabs(diff) < AV_NOSYNC_THRESHOLD &&
                    diff - is->frame_last_filter_delay < 0 &&
                    is->viddec.pkt_serial == is->vidclk.serial &&
                    is->videoq.nb_packets) {
                    is->frame_drops_early++;
                    av_frame_unref(frame);  // 视频帧失去同步则直接扔掉
                    got_picture = 0;
                }
            }
        }
    }

    return got_picture;
}
```
ffplay中framedrop处理有两种，一处是此处解码后得到的frame尚未存入frame队列前，以is->frame_drops_early++为标记；另一处是frame队列中读取frame进行显示的时候，以is->frame_drops_late++为标记。  
本处framedrop操作涉及的变量is->frame_last_filter_delay属于滤镜filter操作相关，ffplay中默认是关闭滤镜的，本文不考虑滤镜相关操作。  

#### 2.4.1 decoder_decode_frame()
这个函数是很核心的一个函数，可以解码视频帧和音频帧。视频解码线程中，视频帧实际的解码操作就在此函数中进行。  
```c
// 从packet_queue中取一个packet，解码生成frame
static int decoder_decode_frame(Decoder *d, AVFrame *frame, AVSubtitle *sub) {
    int ret = AVERROR(EAGAIN);

    for (;;) {
        AVPacket pkt;

        // 本函数被各解码线程(音频、视频、字幕)首次调用时，d->pkt_serial等于-1，d->queue->serial等于1
        if (d->queue->serial == d->pkt_serial) {
            do {
                if (d->queue->abort_request)
                    return -1;

                // 3. 从解码器接收frame
                switch (d->avctx->codec_type) {
                    case AVMEDIA_TYPE_VIDEO:
                        // 3.1 一个视频packet含一个视频frame
                        //     解码器缓存一定数量的packet后，才有解码后的frame输出
                        //     frame输出顺序是按pts的顺序，如IBBPBBP
                        //     frame->pkt_pos变量是此frame对应的packet在视频文件中的偏移地址，值同pkt.pos
                        ret = avcodec_receive_frame(d->avctx, frame);
                        if (ret >= 0) {
                            if (decoder_reorder_pts == -1) {
                                frame->pts = frame->best_effort_timestamp;
                            } else if (!decoder_reorder_pts) {
                                frame->pts = frame->pkt_dts;
                            }
                        }
                        break;
                    case AVMEDIA_TYPE_AUDIO:
                        // 3.2 一个音频packet含多个音频frame，每次avcodec_receive_frame()返回一个frame，此函数返回。
                        // 下次进来此函数，继续获取一个frame，直到avcodec_receive_frame()返回AVERROR(EAGAIN)，
                        // 表示解码器需要填入新的音频packet
                        ret = avcodec_receive_frame(d->avctx, frame);
                        if (ret >= 0) {
                            AVRational tb = (AVRational){1, frame->sample_rate};
                            if (frame->pts != AV_NOPTS_VALUE)
                                frame->pts = av_rescale_q(frame->pts, d->avctx->pkt_timebase, tb);
                            else if (d->next_pts != AV_NOPTS_VALUE)
                                frame->pts = av_rescale_q(d->next_pts, d->next_pts_tb, tb);
                            if (frame->pts != AV_NOPTS_VALUE) {
                                d->next_pts = frame->pts + frame->nb_samples;
                                d->next_pts_tb = tb;
                            }
                        }
                        break;
                }
                if (ret == AVERROR_EOF) {
                    d->finished = d->pkt_serial;
                    avcodec_flush_buffers(d->avctx);
                    return 0;
                }
                if (ret >= 0)
                    return 1;   // 成功解码得到一个视频帧或一个音频帧，则返回
            } while (ret != AVERROR(EAGAIN));
        }

        do {
            if (d->queue->nb_packets == 0)  // packet_queue为空则等待
                SDL_CondSignal(d->empty_queue_cond);
            if (d->packet_pending) {        // 有未处理的packet则先处理
                av_packet_move_ref(&pkt, &d->pkt);
                d->packet_pending = 0;
            } else {
                // 1. 取出一个packet。使用pkt对应的serial赋值给d->pkt_serial
                if (packet_queue_get(d->queue, &pkt, 1, &d->pkt_serial) < 0)
                    return -1;
            }
        } while (d->queue->serial != d->pkt_serial);

        // packet_queue中第一个总是flush_pkt。每次seek操作会插入flush_pkt，更新serial，开启新的播放序列
        if (pkt.data == flush_pkt.data) {
            // 复位解码器内部状态/刷新内部缓冲区。当seek操作或切换流时应调用此函数。
            avcodec_flush_buffers(d->avctx);
            d->finished = 0;
            d->next_pts = d->start_pts;
            d->next_pts_tb = d->start_pts_tb;
        } else {
            if (d->avctx->codec_type == AVMEDIA_TYPE_SUBTITLE) {
                int got_frame = 0;
                ret = avcodec_decode_subtitle2(d->avctx, sub, &got_frame, &pkt);
                if (ret < 0) {
                    ret = AVERROR(EAGAIN);
                } else {
                    if (got_frame && !pkt.data) {
                       d->packet_pending = 1;
                       av_packet_move_ref(&d->pkt, &pkt);
                    }
                    ret = got_frame ? 0 : (pkt.data ? AVERROR(EAGAIN) : AVERROR_EOF);
                }
            } else {
                // 2. 将packet发送给解码器
                //    发送packet的顺序是按dts递增的顺序，如IPBBPBB
                //    pkt.pos变量可以标识当前packet在视频文件中的地址偏移
                if (avcodec_send_packet(d->avctx, &pkt) == AVERROR(EAGAIN)) {
                    av_log(d->avctx, AV_LOG_ERROR, "Receive_frame and send_packet both returned EAGAIN, which is an API violation.\n");
                    d->packet_pending = 1;
                    av_packet_move_ref(&d->pkt, &pkt);
                }
            }
            av_packet_unref(&pkt);
        }
    }
}
```
本函数实现如下功能：  
[1]. 从视频packet队列中取一个packet  
[2]. 将取得的packet发送给解码器  
[3]. 从解码器接收解码后的frame，此frame作为函数的输出参数供上级函数处理  
注意如下几点：  
[1]. 含B帧的视频文件，其视频帧存储顺序与显示顺序不同，参[]  
[2]. 解码器的输入是packet队列，视频帧解码顺序与存储顺序相同，是按dts递增的顺序。dts是解码时间戳，因此存储顺序解码顺序都是dts递增的顺序。avcodec_send_packet()就是将视频文件中的packet序列依次发送给解码器。发送packet的顺序如IPBBPBB。  
[3]. 解码器的输出是frame队列，frame输出顺序是按pts递增的顺序。pts是解码时间戳。pts与dts不一致的问题由解码器进行了处理，用户程序不必关心。从解码器接收frame的顺序如IBBPBBP。  
[4]. 解码器中会缓存一定数量的帧，一个新的解码动作启动后，向解码器送入好几个packet解码器才会输出第一个packet，这比较容易理解，因为解码时帧之间有信赖关系，例如IPB三个帧被送入解码器后，B帧解码需要依赖I帧和P帧，所在在B帧输出前，I帧和P帧必须存在于解码器中而不能删除。理解了这一点，后面视频frame队列中对视频帧的显示和删除机制才容易理解。  

如何确定解码器的输出frame与输入packet的对应关系呢？可以对比frame->pkt_pos和pkt.pos的值，这两个值表示packet在视频文件中的偏移地址，如果这两个变量值相等，表示此frame来自此packet。调试跟踪这两个变量值，即能发现解码器输入帧与输出帧的关系。为简便，就不贴图了。  

### 2.5 音频解码线程：audio_thread()
**音频解码线程从音频packet队列中取数据，解码后存入音频frame队列**  

### 2.6 字幕解码线程：subtitle_thread()
略。以后有机会研究字幕时，再作补充。

### 2.7 音频播放幕后线程


## 2. 音视频同步  
### 2.1 实验平台


### 2.2 源码流程分析  
本实验仅播放视频文件中的声音，而不显示图像。源码流程参考如下：  
![FFmpeg简易播放器-音频播放流程图](https://leihl.github.io/img/ffmpeg_player/02_player_audio_flow.jpg "FFmpeg简易播放器-音频播放流程图")  

### 2.3 关键函数  
几个关键函数的说明直接写在代码注释里：  
#### 2.3.1 开启音频处理子线程  
```c
// 打开音频设备并创建音频处理线程。期望的参数是wanted_spec，实际得到的硬件参数是actual_spec
// 1) SDL提供两种使音频设备取得音频数据方法：
//    a. push，SDL以特定的频率调用回调函数，在回调函数中取得音频数据
//    b. pull，用户程序以特定的频率调用SDL_QueueAudio()，向音频设备提供数据。此种情况wanted_spec.callback=NULL
// 2) 音频设备打开后播放静音，不启动回调，调用SDL_PauseAudio(0)后启动回调，开始正常播放音频
SDL_AudioSpec wanted_spec;
SDL_AudioSpec actual_spec;
wanted_spec.freq = p_codec_ctx->sample_rate;    // 采样率
wanted_spec.format = AUDIO_S16SYS;              // S表带符号，16是采样深度，SYS表采用系统字节序
wanted_spec.channels = p_codec_ctx->channels;   // 声音通道数
wanted_spec.silence = 0;                        // 静音值
wanted_spec.samples = SDL_AUDIO_BUFFER_SIZE;    // SDL声音缓冲区尺寸，单位是单声道采样点尺寸x通道数
wanted_spec.callback = audio_callback;          // 回调函数，若为NULL，则应使用SDL_QueueAudio()机制
wanted_spec.userdata = p_codec_ctx;             // 提供给回调函数的参数
SDL_OpenAudio(&wanted_spec, &actual_spec);
```
#### 2.3.2 启动音频回调机制  
```c
// 暂停/继续音频回调处理。参数1表暂停，0表继续。
// 打开音频设备后默认未启动回调处理，通过调用SDL_PauseAudio(0)来启动回调处理。
// 这样就可以在打开音频设备后先为回调函数安全初始化数据，一切就绪后再启动音频回调。
// 在暂停期间，会将静音值往音频设备写。
SDL_PauseAudio(0);
```
#### 2.3.3 音频回调函数  
用户实现的函数，由SDL音频处理子线程回调  
```c
// 音频处理回调函数。读队列获取音频包，解码，播放
// 此函数被SDL按需调用，此函数不在用户主线程中，因此数据需要保护
// \param[in]  userdata用户在注册回调函数时指定的参数
// \param[out] stream 音频数据缓冲区地址，将解码后的音频数据填入此缓冲区
// \param[out] len    音频数据缓冲区大小，单位字节
// 回调函数返回后，stream指向的音频缓冲区将变为无效
// 双声道采样点的顺序为LRLRLR
void audio_callback(void *userdata, uint8_t *stream, int len)
{
    ...
}
```
#### 2.3.4 音频包队列读写函数  
用户实现的函数，主线程向队列尾部写音频包，SDL音频处理子线程(回调函数处理)从队列头部取出音频包
```c
// 写队列尾部
int packet_queue_push(packet_queue_t *q, AVPacket *pkt)
{
    ...
}

// 读队列头部
int packet_queue_pop(packet_queue_t *q, AVPacket *pkt, int block)
{
    ...
}
```
#### 2.3.5 音频解码  
音频解码功能封装为一个函数，将一个音频packet解码后得到的声音数据传递给输出缓冲区。此处的输出缓冲区audio_buf会由上一级调用函数audio_callback()在返回时将缓冲区数据提供给音频设备。  
```c
int audio_decode_frame(AVCodecContext *p_codec_ctx, AVPacket *p_packet, uint8_t *audio_buf, int buf_size)
{
    AVFrame *p_frame = av_frame_alloc();
    
    int frm_size = 0;
    int ret_size = 0;
    int ret;

    // 1 向解码器喂数据，每次喂一个packet
    ret = avcodec_send_packet(p_codec_ctx, p_packet);
    if (ret != 0)
    {
        printf("avcodec_send_packet() failed %d\n", ret);
        av_packet_unref(p_packet);
        return -1;
    }

    ret_size = 0;
    while (1)
    {
        // 2 接收解码器输出的数据，每次接收一个frame
        ret = avcodec_receive_frame(p_codec_ctx, p_frame);
        if (ret != 0)
        {
            if (ret == AVERROR_EOF)
            {
                printf("audio avcodec_receive_frame(): the decoder has been fully flushed\n");
                return 0;
            }
            else if (ret == AVERROR(EAGAIN))
            {
                printf("audio avcodec_receive_frame(): output is not available in this state - "
                       "user must try to send new input\n");
                break;
            }
            else if (ret == AVERROR(EINVAL))
            {
                printf("audio avcodec_receive_frame(): codec not opened, or it is an encoder\n");
            }
            else
            {
                printf("audio avcodec_receive_frame(): legitimate decoding errors\n");
            }
        }

        // 3. 根据相应音频参数，获得所需缓冲区大小
        frm_size = av_samples_get_buffer_size(
                NULL, 
                p_codec_ctx->channels,
                p_frame->nb_samples,
                p_codec_ctx->sample_fmt,
                1);

        printf("frame size %d, buffer size %d\n", frm_size, buf_size);
        assert(frm_size <= buf_size);
        
        // 4. 将音频帧拷贝到函数输出参数audio_buf
        memcpy(audio_buf, p_frame->data[0], frm_size);
        
        if (frm_size > 0)
        {
            ret_size += frm_size;
        }
    }

    av_frame_unref(p_frame);
    
    return ret_size;
}
```
注意：  
[1]. 一个音频packet中含有多个完整的音频帧，因此一次avcodec_send_packet()后，会多次调用avcodec_receive_frame()来将这一个packet解码后的数据接收完。  
[2]. 解码器内部会有缓冲机制，会缓存一定量的音频帧，不冲洗(flush)解码器的话，缓存帧是取不出来的，未冲洗(flush)解码器情况下，avcodec_receive_frame()返回AVERROR(EAGAIN)，表示解码器中改取的帧已取完了(当然缓存帧还是在的)，需要用avcodec_send_packet()向解码器提供新数据。  
[3]. 文件播放完毕时，应冲洗(flush)解码器。冲洗(flush)解码器的方法就是调用avcodec_send_packet(..., NULL)，然后按之前同样的方式多次调用avcodec_receive_frame()将缓存帧取尽。缓存帧取完后，avcodec_receive_frame()返回AVERROR_EOF。  

### 2.4 源码清单  
代码已经变得挺长了，不贴完整源码了，源码参考：  
<https://github.com/leihl/leihl.github.io/blob/master/source/ffmpeg/player_audio/ffplayer.c>  

源码清单中涉及的一些概念简述如下：  
**container:**  
对应数据结构AVFormatContext  
封装器，将流数据封装为指定格式的文件，文件格式如AVI、MP4等。  
FFmpeg可识别五种流类型：视频video(v)、音频audio(a)、attachment(t)、数据data(d)、字幕subtitle。  

**codec:**  
对应数据结构AVCodec  
编解码器。编码器将未压缩的原始图像或音频数据编码为压缩数据。解码器与之相反。  

**codec context**:  
对应数据结构AVCodecContext  
编解码器上下文。此为非常重要的一个数据结构，后文分析。各API大量使用AVCodecContext来引用编解码器。  

**codec par**:  
对应数据结构AVCodecParameters  
编解码器参数。新版本增加的字段。新版本建议使用AVStream->codepar替代AVStream->codec。  

**packet**:  
对应数据结构AVPacket  
经过编码的数据。通过av_read_frame()从媒体文件中获取得到的一个packet可能包含多个(整数个)音频帧或单个
视频帧，或者其他类型的流数据。  

**frame**:  
对应数据结构AVFrame  
解码后的原始数据。解码器将packet解码后生成frame。  

### 2.3 编译
```shell
gcc -o ffplayer ffplayer.c -lavutil -lavformat -lavcodec -lavutil -lswscale -lSDL2
```

### 2.4 测试
选用clock_320.avi测试文件，此文件
```shell
ffprobe clock_320.avi
```
打印视频文件信息如下：  
```shell
[avi @ 0x9286c0] non-interleaved AVI
Input #0, avi, from 'clock_320.avi':
  Duration: 00:00:12.00, start: 0.000000, bitrate: 42 kb/s
    Stream #0:0: Video: msrle ([1][0][0][0] / 0x0001), pal8, 320x320, 1 fps, 1 tbr, 1 tbn, 1 tbc
    Stream #0:1: Audio: truespeech ([34][0][0][0] / 0x0022), 8000 Hz, mono, s16, 8 kb/s
```

运行测试命令：  
```shell
./ffplayer clock_320.avi 
```
可以听到每隔1秒播放一次“嘀”声，播放12次后播放结束。播放过程只有声音，没有图像窗口。播放正常。

## 3. 参考资料  
[1] 雷霄骅，[视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)  
[2] 雷霄骅，[最简单的基于FFMPEG+SDL的视频播放器ver2(采用SDL2.0)](https://blog.csdn.net/leixiaohua1020/article/details/38868499)  
[3] SDL WIKI, <https://wiki.libsdl.org/>  
[4] Martin Bohme, [An ffmpeg and SDL Tutorial, Tutorial 05: Synching Video](http://dranger.com/ffmpeg/ffmpegtutorial_all.html#tutorial05.html)  

http://www.cnblogs.com/zhangming-blog/articles/6000518.html  
https://blog.csdn.net/abcsunl/article/details/68190136  
https://www.jianshu.com/p/04b5b1e4ff27  
https://blog.csdn.net/aokewood/article/details/6893699  

## 4. 修改记录  
2018-12-28  V1.0  初稿  