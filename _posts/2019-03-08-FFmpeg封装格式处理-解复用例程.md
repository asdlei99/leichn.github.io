## 1. 概述  

封装格式可以看作是编码流(音频流、视频流等)数据的一层外壳，将编码后的数据存储于此封装格式的文件之内。封装格式又称容器，容器的称法更为形象，所谓容器，就是存放内容的器具，饮料是内容，那么装饮料的瓶子就是容器。  

不同的封装格式一般由文件扩展名标识。不同封装格式支持的编码格式不一样。几个常用的封装格式如下：  
下表引用自“[视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)”
| 名称(文件扩展名)  |推出机构         |流媒体|支持的视频编码|支持的音频编码|目前使用领域|
| :------           | :------         | :----|:----         |:----|:----|
|AVI(.avi)          |Microsoft公司    |不支持|几乎所有格式|几乎所有格式|BT下载影视|
|MP4(.mp4)          |MPEG组织         |支持  |MPEG-2/MPEG-4/H.264/H.263等|AAC/MPEG-1 Layers I,II,III/AC-3等|互联网视频网站|
|TS(.ts)            |MPEG组织         |支持  |MPEG-1/MPEG-2/MPEG-4/H.264|MPEG-1 Layers I,II,III/AAC|IPTV，数字电视|
|Flash Video(.flv)  |Adobe公司        |支持  |Sorenson/VP6/H.264|MP3/ADPCM/Linear PCM/AAC等|互联网视频网站|
|Matroska(.mkv)     |CoreCodec公司    |支持  |几乎所有格式|几乎所有格式|互联网视频网站|
|Real Video(.rmvb)  |Real Networks公司|支持  |RealVideo 8,9,10|AAC/Cook Codec/RealAudio Lossless|BT下载影视|

FFmpeg关于封装格式的处理涉及打开输入文件、打开输出文件、从输入文件读取编码帧、往输出文件写入编码帧，这些都不涉及编码解码层面。  
本文研究FFmpeg中解复用(demux，或称解封装)编程方法。mux指复用，是multiplex的缩写，表示将多路流(视频、音频、字幕等)混入一路输出中(普通文件、流等)。demux指解复用，是mux的反操作，表示从一路输入中分离出多路流(视频、音频、字幕等)。  

## 2. API  
### 2.1 av_read_frame()  
```  
/**
 * Return the next frame of a stream.
 * This function returns what is stored in the file, and does not validate
 * that what is there are valid frames for the decoder. It will split what is
 * stored in the file into frames and return one for each call. It will not
 * omit invalid data between valid frames so as to give the decoder the maximum
 * information possible for decoding.
 *
 * If pkt->buf is NULL, then the packet is valid until the next
 * av_read_frame() or until avformat_close_input(). Otherwise the packet
 * is valid indefinitely. In both cases the packet must be freed with
 * av_packet_unref when it is no longer needed. For video, the packet contains
 * exactly one frame. For audio, it contains an integer number of frames if each
 * frame has a known fixed size (e.g. PCM or ADPCM data). If the audio frames
 * have a variable size (e.g. MPEG audio), then it contains one frame.
 *
 * pkt->pts, pkt->dts and pkt->duration are always set to correct
 * values in AVStream.time_base units (and guessed if the format cannot
 * provide them). pkt->pts can be AV_NOPTS_VALUE if the video format
 * has B-frames, so it is better to rely on pkt->dts if you do not
 * decompress the payload.
 *
 * @return 0 if OK, < 0 on error or end of file
 */
int av_read_frame(AVFormatContext *s, AVPacket *pkt);
```  
FFmpeg中将编码帧及未编码帧均称作frame，这里为方便，将编码帧称作packet，未编码帧称作frame。  

`av_read_frame()`将存储在输入文件中的数据分割为多个packet，每次调用将得到一个packet。packet可能是视频帧、音频帧或其他数据，解码器只会解码视频帧或音频帧，非音视频数据并不会被扔掉、从而能向解码器提供尽可能多的信息。  

对于视频来说，一个packet只包含一个frame；对于音频来说，若是帧长固定的格式则一个packet可包含整数个frame，若是帧长可变的格式则一个packet只包含一个frame。  

读取到的packet每次使用完之后应调用`av_packet_unref(AVPacket *pkt)`清空packet。否则会千万内存泄露。  

## 3. 实现  

### 3.1 源码  
源码很短，用于演示demux的用法。实现的功能是，将输入文件中的视频流和音频流分离出来，保存为单独的文件，所保存的文件是不含封装格式的裸流文件。  
```c  
#include <libavformat/avformat.h>

int main (int argc, char **argv)
{
    if (argc != 4)
    {
        fprintf(stderr, "usage: %s test.avi test.mpeg2video test.mp2\n", argv[0]);
        exit(1);
    }

    const char *input_fname = argv[1];
    const char *output_v_fname = argv[2];
    const char *output_a_fname = argv[3];
    FILE *video_dst_file = fopen(output_v_fname, "wb");
    FILE *audio_dst_file = fopen(output_a_fname, "wb");

    AVFormatContext *fmt_ctx = NULL;
    int ret = avformat_open_input(&fmt_ctx, input_fname, NULL, NULL);
    if (ret < 0) {
        fprintf(stderr, "Could not open input file %s\n", input_fname);
        exit(1);
    }

    int video_idx = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);
    int audio_idx = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_AUDIO, -1, -1, NULL, 0);

    av_dump_format(fmt_ctx, 0, input_fname, 0);

    AVPacket pkt;
    av_init_packet(&pkt);
    pkt.data = NULL;
    pkt.size = 0;

    while (av_read_frame(fmt_ctx, &pkt) >= 0)
    {
        if (pkt.stream_index == video_idx)
        {
            ret = fwrite(pkt.data, 1, pkt.size, video_dst_file);
            printf("Write video packet %x %3"PRId64" (size=%5d)\n", pkt.pos, pkt.pts, ret);
        }
        else if (pkt.stream_index == audio_idx) {
            ret = fwrite(pkt.data, 1, pkt.size, audio_dst_file);
            printf("Write audio packet %x %3"PRId64" (size=%5d)\n", pkt.pos, pkt.pts, ret);
        }
        av_packet_unref(&pkt);
    }

    printf("Demuxing succeeded.\n");

    avformat_close_input(&fmt_ctx);
    fclose(video_dst_file);
    fclose(audio_dst_file);

    return 0;
}
```  

### 3.2 编译  
源文件为demuxing.c，在SHELL中执行如下编译命令：  
```sh  
gcc -o demuxing demuxing.c -lavformat -lavcodec
```
生成可执行文件demuxing  

### 3.3 验证  
本节代码仅实现了最简单的功能，有些编码格式及封装格式分离出来的音视频文件无法正常播放。所以测试用的视频文件是特殊选取的，文件下载：“[]()”  

看一下测试用资源文件的格式：  
```sh  
```  

测试：  
```  
./demuxing test.avi test.mpeg2video test.mp2
```

## 4. 扩展

## 5. 参考资料  
[1] WIKI，[Digital_container_format](https://en.wikipedia.org/wiki/Digital_container_format)  
[2] WIKI，[Comparison_of_container_formats](https://en.wikipedia.org/wiki/Comparison_of_container_formats)  
[3] 雷霄骅，[使用FFMPEG类库分离出多媒体文件中的H.264码流](https://blog.csdn.net/leixiaohua1020/article/details/11800877)，<https://blog.csdn.net/leixiaohua1020/article/details/11800877>  

## 6. 修改记录  
2019-03-08  V1.0  初稿  
